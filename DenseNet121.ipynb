{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WZCPEHBkCn-",
        "outputId": "9ec0f54c-cb8f-4023-d9c0-5d3f63db9a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "# Load DenseNet121 model with pre-trained weights\n",
        "densenet = DenseNet121(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "# Freeze the layers\n",
        "for layer in densenet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top\n",
        "x = Flatten()(densenet.output)\n",
        "prediction = Dense((4), activation='softmax')(x)\n",
        "model_densenet = Model(inputs=densenet.input, outputs=prediction)\n",
        "\n",
        "# Compile the model\n",
        "model_densenet.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Prepare data generators with DenseNet preprocessing\n",
        "train_datagen_densenet = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen_densenet = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    preprocessing_function=preprocess_input\n",
        ")\n",
        "\n",
        "training_set_densenet = train_datagen_densenet.flow_from_directory(\n",
        "    '/content/drive/MyDrive/plant/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_set_densenet = test_datagen_densenet.flow_from_directory(\n",
        "    '/content/drive/MyDrive/plant/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "r_densenet = model_densenet.fit(\n",
        "    training_set_densenet,\n",
        "    validation_data=test_set_densenet,\n",
        "    epochs=20,\n",
        "    steps_per_epoch=len(training_set_densenet),\n",
        "    validation_steps=len(test_set_densenet)\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss_densenet, test_accuracy_densenet = model_densenet.evaluate(test_set_densenet, steps=len(test_set_densenet))\n",
        "print(f\"DenseNet121 Test Loss: {test_loss_densenet:.4f}\")\n",
        "print(f\"DenseNet121 Test Accuracy: {test_accuracy_densenet:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOSiAkHgkKbr",
        "outputId": "ee127f72-a917-4805-b0d8-ea5c19279e0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1981 images belonging to 4 classes.\n",
            "Found 18 images belonging to 4 classes.\n",
            "Epoch 1/20\n",
            "62/62 [==============================] - 767s 12s/step - loss: 1.3128 - accuracy: 0.5109 - val_loss: 1.1187 - val_accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "62/62 [==============================] - 406s 7s/step - loss: 0.8553 - accuracy: 0.6436 - val_loss: 0.7066 - val_accuracy: 0.8889\n",
            "Epoch 3/20\n",
            "62/62 [==============================] - 404s 6s/step - loss: 0.7553 - accuracy: 0.6971 - val_loss: 0.6480 - val_accuracy: 0.6667\n",
            "Epoch 4/20\n",
            "62/62 [==============================] - 405s 7s/step - loss: 0.7078 - accuracy: 0.7052 - val_loss: 0.7938 - val_accuracy: 0.6111\n",
            "Epoch 5/20\n",
            "62/62 [==============================] - 418s 7s/step - loss: 0.6455 - accuracy: 0.7395 - val_loss: 0.5297 - val_accuracy: 0.7222\n",
            "Epoch 6/20\n",
            "62/62 [==============================] - 429s 7s/step - loss: 0.6480 - accuracy: 0.7350 - val_loss: 0.4172 - val_accuracy: 0.8333\n",
            "Epoch 7/20\n",
            "62/62 [==============================] - 417s 7s/step - loss: 0.6368 - accuracy: 0.7511 - val_loss: 0.6467 - val_accuracy: 0.7778\n",
            "Epoch 8/20\n",
            "62/62 [==============================] - 397s 6s/step - loss: 0.5502 - accuracy: 0.7819 - val_loss: 0.3734 - val_accuracy: 0.8333\n",
            "Epoch 9/20\n",
            "62/62 [==============================] - 410s 7s/step - loss: 0.6310 - accuracy: 0.7314 - val_loss: 0.6021 - val_accuracy: 0.7778\n",
            "Epoch 10/20\n",
            "62/62 [==============================] - 403s 6s/step - loss: 0.5425 - accuracy: 0.7824 - val_loss: 0.2927 - val_accuracy: 0.8333\n",
            "Epoch 11/20\n",
            "62/62 [==============================] - 404s 6s/step - loss: 0.5300 - accuracy: 0.7910 - val_loss: 0.5400 - val_accuracy: 0.7222\n",
            "Epoch 12/20\n",
            "62/62 [==============================] - 392s 6s/step - loss: 0.5322 - accuracy: 0.7915 - val_loss: 0.3362 - val_accuracy: 0.7778\n",
            "Epoch 13/20\n",
            "62/62 [==============================] - 397s 6s/step - loss: 0.5078 - accuracy: 0.7850 - val_loss: 0.3936 - val_accuracy: 0.7778\n",
            "Epoch 14/20\n",
            "62/62 [==============================] - 457s 7s/step - loss: 0.5277 - accuracy: 0.7845 - val_loss: 0.2839 - val_accuracy: 0.9444\n",
            "Epoch 15/20\n",
            "62/62 [==============================] - 425s 7s/step - loss: 0.4965 - accuracy: 0.8067 - val_loss: 0.2773 - val_accuracy: 0.8889\n",
            "Epoch 16/20\n",
            "62/62 [==============================] - 383s 6s/step - loss: 0.4660 - accuracy: 0.8097 - val_loss: 0.4352 - val_accuracy: 0.6667\n",
            "Epoch 17/20\n",
            "62/62 [==============================] - 395s 6s/step - loss: 0.5506 - accuracy: 0.7774 - val_loss: 0.4047 - val_accuracy: 0.8333\n",
            "Epoch 18/20\n",
            "62/62 [==============================] - 394s 6s/step - loss: 0.4745 - accuracy: 0.8102 - val_loss: 0.3570 - val_accuracy: 0.8333\n",
            "Epoch 19/20\n",
            "62/62 [==============================] - 398s 6s/step - loss: 0.4534 - accuracy: 0.8279 - val_loss: 0.2948 - val_accuracy: 0.8333\n",
            "Epoch 20/20\n",
            "62/62 [==============================] - 384s 6s/step - loss: 0.5978 - accuracy: 0.7587 - val_loss: 0.3579 - val_accuracy: 0.8333\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.3579 - accuracy: 0.8333\n",
            "DenseNet121 Test Loss: 0.3579\n",
            "DenseNet121 Test Accuracy: 0.8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mfBpgqqVkqPf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}